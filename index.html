<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>魚検出デモ</title>
  <style>
    body { margin: 0; overflow: hidden; }
    #video, #overlay {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: auto;
      max-height: 100vh;
    }
    #countBox {
      position: absolute;
      top: 10px; right: 10px;
      font-size: 24px;
      color: #0f0;
      text-shadow: 1px 1px 2px #000;
      background: rgba(0,0,0,0.3);
      padding: 4px 8px;
      border-radius: 4px;
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="overlay"></canvas>
  <div id="countBox">魚: 0</div>

  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
  <script>
    const MODEL_URL = 'path/to/your/fish_model/model.json'; 
    let model, video, canvas, ctx, countBox;

    async function setupCamera() {
      video = document.getElementById('video');
      // スマホ背面（environment）、それ以外はデフォルトカメラ
      const constraints = {
        video: {
          facingMode: { ideal: "environment" },
          width: { ideal: 1280 },
          height: { ideal: 720 }
        }
      };
      try {
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = stream;
      } catch (e) {
        console.warn("背面カメラが利用できませんでした。デフォルトカメラを使用します。", e);
        const fallback = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = fallback;
      }
      return new Promise(resolve => {
        video.onloadedmetadata = () => {
          video.play();
          resolve();
        };
      });
    }

    async function loadModel() {
      model = await tf.loadGraphModel(MODEL_URL);
      console.log('モデル読み込み完了');
    }

    function preprocessVideoFrame() {
      const input = tf.browser.fromPixels(video);
      const resized = tf.image.resizeBilinear(input, [320, 320]);
      const normalized = resized.div(255.0);
      return normalized.expandDims(0);
    }

    async function detectFrame() {
      if (!model) return;
      const inputTensor = preprocessVideoFrame();
      const result = await model.executeAsync(inputTensor);
      tf.dispose(inputTensor);

      const [boxes, scores, classes] = result;
      const boxesData = boxes.dataSync();
      const scoresData = scores.dataSync();
      const classesData = classes.dataSync();

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      let fishCount = 0;
      const threshold = 0.5;

      for (let i = 0; i < scoresData.length; i++) {
        if (scoresData[i] > threshold && Math.round(classesData[i]) === 1) {
          fishCount++;
          const ymin = boxesData[i*4]   * video.videoHeight;
          const xmin = boxesData[i*4+1] * video.videoWidth;
          const ymax = boxesData[i*4+2] * video.videoHeight;
          const xmax = boxesData[i*4+3] * video.videoWidth;
          const w = xmax - xmin, h = ymax - ymin;
          ctx.lineWidth = 4;
          ctx.strokeStyle = '#0f0';
          ctx.strokeRect(xmin, ymin, w, h);
        }
      }

      countBox.textContent = `魚: ${fishCount}`;
      tf.dispose(result);
      requestAnimationFrame(detectFrame);
    }

    async function main() {
      await setupCamera();
      canvas = document.getElementById('overlay');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx = canvas.getContext('2d');
      countBox = document.getElementById('countBox');
      await loadModel();
      detectFrame();
    }

    window.addEventListener('DOMContentLoaded', main);
  </script>
</body>
</html>
