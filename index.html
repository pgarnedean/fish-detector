<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>カメラ動体検知デモ2</title>
  <style>
    body { margin: 0; overflow: hidden; }
    #canvasOutput { position: absolute; top: 0; left: 0; }
    #count { position: absolute; top: 10px; right: 20px; font-size: 24px; color: #00FF00; font-weight: bold; }
    #video { display: none; }
  </style>
</head>
<body>
  <video id="video" playsinline autoplay muted></video>
  <canvas id="canvasOutput"></canvas>
  <div id="count">0</div>

  <!-- OpenCV.js の読み込み。読み込み完了後 onOpenCvReady を呼び出します -->
  <script async src="https://docs.opencv.org/4.7.0/opencv.js" onload="onOpenCvReady()"></script>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvasOutput');
    const ctx = canvas.getContext('2d');
    const countElem = document.getElementById('count');

    function startCamera() {
      navigator.mediaDevices.getUserMedia({ video: true })
        .then(stream => {
          video.srcObject = stream;
        })
        .catch(err => console.error('カメラアクセスエラー:', err));
    }

    function onOpenCvReady() {
      console.log('OpenCV.js loaded');
      startCamera();
      video.addEventListener('loadedmetadata', () => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // OpenCV用マトリクス
        const cap = new cv.VideoCapture(video);
        const frame = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
        const gray = new cv.Mat();
        const prevGray = new cv.Mat();
        const diff = new cv.Mat();
        const thresh = new cv.Mat();
        const M = cv.Mat.ones(5, 5, cv.CV_8U);
        const contours = new cv.MatVector();
        const hierarchy = new cv.Mat();

        // 最初のフレームをグレースケール化
        cap.read(frame);
        cv.cvtColor(frame, prevGray, cv.COLOR_RGBA2GRAY);

        function processFrame() {
          cap.read(frame);
          cv.cvtColor(frame, gray, cv.COLOR_RGBA2GRAY);
          cv.absdiff(gray, prevGray, diff);
          cv.threshold(diff, thresh, 25, 255, cv.THRESH_BINARY);
          cv.morphologyEx(thresh, thresh, cv.MORPH_OPEN, M);
          cv.findContours(thresh, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

          ctx.drawImage(video, 0, 0);
          let count = 0;
          for (let i = 0; i < contours.size(); i++) {
            const rect = cv.boundingRect(contours.get(i));
            if (rect.width * rect.height < 500) continue;
            ctx.strokeStyle = '#00FF00';
            ctx.lineWidth = 2;
            ctx.strokeRect(rect.x, rect.y, rect.width, rect.height);
            count++;
          }
          countElem.textContent = count;

          gray.copyTo(prevGray);
          requestAnimationFrame(processFrame);
        }

        requestAnimationFrame(processFrame);
      });
    }
  </script>
</body>
</html>
